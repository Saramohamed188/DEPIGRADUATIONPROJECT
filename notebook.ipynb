{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T21:14:20.154192Z","iopub.status.busy":"2024-10-13T21:14:20.153810Z","iopub.status.idle":"2024-10-13T21:18:41.926575Z","shell.execute_reply":"2024-10-13T21:18:41.925330Z","shell.execute_reply.started":"2024-10-13T21:14:20.154159Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100 completed. Discriminator Loss: 0.4342, Generator Loss: 2.4106\n","Epoch 2/100 completed. Discriminator Loss: 0.3077, Generator Loss: 3.8353\n","Epoch 3/100 completed. Discriminator Loss: 0.2431, Generator Loss: 4.4933\n","Epoch 4/100 completed. Discriminator Loss: 0.2057, Generator Loss: 4.6861\n","Epoch 5/100 completed. Discriminator Loss: 0.1822, Generator Loss: 4.6642\n","Epoch 6/100 completed. Discriminator Loss: 0.1611, Generator Loss: 4.7831\n","Epoch 7/100 completed. Discriminator Loss: 0.1411, Generator Loss: 5.0418\n","Epoch 8/100 completed. Discriminator Loss: 0.1241, Generator Loss: 5.3426\n","Epoch 9/100 completed. Discriminator Loss: 0.1089, Generator Loss: 5.6584\n","Epoch 10/100 completed. Discriminator Loss: 0.0950, Generator Loss: 6.0107\n","Epoch 11/100 completed. Discriminator Loss: 0.0822, Generator Loss: 6.4063\n","Epoch 12/100 completed. Discriminator Loss: 0.0696, Generator Loss: 6.8486\n","Epoch 13/100 completed. Discriminator Loss: 0.0574, Generator Loss: 7.3217\n","Epoch 14/100 completed. Discriminator Loss: 0.0461, Generator Loss: 7.7724\n","Epoch 15/100 completed. Discriminator Loss: 0.0361, Generator Loss: 8.2174\n","Epoch 16/100 completed. Discriminator Loss: 0.0266, Generator Loss: 8.6721\n","Epoch 17/100 completed. Discriminator Loss: 0.0187, Generator Loss: 9.0173\n","Epoch 18/100 completed. Discriminator Loss: 0.0129, Generator Loss: 9.2079\n","Epoch 19/100 completed. Discriminator Loss: 0.0086, Generator Loss: 9.3423\n","Epoch 20/100 completed. Discriminator Loss: 0.0061, Generator Loss: 9.3459\n","Epoch 21/100 completed. Discriminator Loss: 0.0050, Generator Loss: 9.2686\n","Epoch 22/100 completed. Discriminator Loss: 0.0019, Generator Loss: 9.4156\n","Epoch 23/100 completed. Discriminator Loss: -0.0063, Generator Loss: 10.0073\n","Epoch 24/100 completed. Discriminator Loss: -0.0165, Generator Loss: 10.8010\n","Epoch 25/100 completed. Discriminator Loss: -0.0172, Generator Loss: 11.0196\n","Epoch 26/100 completed. Discriminator Loss: -0.0079, Generator Loss: 10.7497\n","Epoch 27/100 completed. Discriminator Loss: -0.0009, Generator Loss: 10.4956\n","Epoch 28/100 completed. Discriminator Loss: 0.0062, Generator Loss: 10.2688\n","Epoch 29/100 completed. Discriminator Loss: 0.0126, Generator Loss: 10.0752\n","Epoch 30/100 completed. Discriminator Loss: 0.0173, Generator Loss: 9.9167\n","Epoch 31/100 completed. Discriminator Loss: 0.0206, Generator Loss: 9.7941\n","Epoch 32/100 completed. Discriminator Loss: 0.0212, Generator Loss: 9.7966\n","Epoch 33/100 completed. Discriminator Loss: 0.0179, Generator Loss: 10.0901\n","Epoch 34/100 completed. Discriminator Loss: 0.0086, Generator Loss: 10.8764\n","Epoch 35/100 completed. Discriminator Loss: -0.0077, Generator Loss: 12.2251\n","Epoch 36/100 completed. Discriminator Loss: -0.0300, Generator Loss: 14.0567\n","Epoch 37/100 completed. Discriminator Loss: -0.0539, Generator Loss: 16.0235\n","Epoch 38/100 completed. Discriminator Loss: -0.0647, Generator Loss: 17.0303\n","Epoch 39/100 completed. Discriminator Loss: -0.0567, Generator Loss: 16.8962\n","Epoch 40/100 completed. Discriminator Loss: -0.0466, Generator Loss: 16.6350\n","Epoch 41/100 completed. Discriminator Loss: -0.0398, Generator Loss: 16.3804\n","Epoch 42/100 completed. Discriminator Loss: -0.0328, Generator Loss: 16.1329\n","Epoch 43/100 completed. Discriminator Loss: -0.0259, Generator Loss: 15.8826\n","Epoch 44/100 completed. Discriminator Loss: -0.0153, Generator Loss: 15.6344\n","Epoch 45/100 completed. Discriminator Loss: -0.0034, Generator Loss: 15.3919\n","Epoch 46/100 completed. Discriminator Loss: 0.0095, Generator Loss: 15.1563\n","Epoch 47/100 completed. Discriminator Loss: 0.0186, Generator Loss: 14.9316\n","Epoch 48/100 completed. Discriminator Loss: 0.0262, Generator Loss: 14.7277\n","Epoch 49/100 completed. Discriminator Loss: 0.0315, Generator Loss: 14.5447\n","Epoch 50/100 completed. Discriminator Loss: 0.0355, Generator Loss: 14.3767\n","Epoch 51/100 completed. Discriminator Loss: 0.0384, Generator Loss: 14.2257\n","Epoch 52/100 completed. Discriminator Loss: 0.0403, Generator Loss: 14.1103\n","Epoch 53/100 completed. Discriminator Loss: 0.0418, Generator Loss: 13.9855\n","Epoch 54/100 completed. Discriminator Loss: 0.0449, Generator Loss: 13.8331\n","Epoch 55/100 completed. Discriminator Loss: 0.0487, Generator Loss: 13.6774\n","Epoch 56/100 completed. Discriminator Loss: 0.0517, Generator Loss: 13.5250\n","Epoch 57/100 completed. Discriminator Loss: 0.0540, Generator Loss: 13.3796\n","Epoch 58/100 completed. Discriminator Loss: 0.0559, Generator Loss: 13.2395\n","Epoch 59/100 completed. Discriminator Loss: 0.0582, Generator Loss: 13.1003\n","Epoch 60/100 completed. Discriminator Loss: 0.0603, Generator Loss: 12.9621\n","Epoch 61/100 completed. Discriminator Loss: 0.0622, Generator Loss: 12.8266\n","Epoch 62/100 completed. Discriminator Loss: 0.0641, Generator Loss: 12.6905\n","Epoch 63/100 completed. Discriminator Loss: 0.0661, Generator Loss: 12.5537\n","Epoch 64/100 completed. Discriminator Loss: 0.0673, Generator Loss: 12.4249\n","Epoch 65/100 completed. Discriminator Loss: 0.0681, Generator Loss: 12.2991\n","Epoch 66/100 completed. Discriminator Loss: 0.0684, Generator Loss: 12.1813\n","Epoch 67/100 completed. Discriminator Loss: 0.0686, Generator Loss: 12.0684\n","Epoch 68/100 completed. Discriminator Loss: 0.0685, Generator Loss: 11.9599\n","Epoch 69/100 completed. Discriminator Loss: 0.0685, Generator Loss: 11.8591\n","Epoch 70/100 completed. Discriminator Loss: 0.0677, Generator Loss: 11.7898\n","Epoch 71/100 completed. Discriminator Loss: 0.0666, Generator Loss: 11.7441\n","Epoch 72/100 completed. Discriminator Loss: 0.0652, Generator Loss: 11.7224\n","Epoch 73/100 completed. Discriminator Loss: 0.0638, Generator Loss: 11.6962\n","Epoch 74/100 completed. Discriminator Loss: 0.0628, Generator Loss: 11.6590\n","Epoch 75/100 completed. Discriminator Loss: 0.0615, Generator Loss: 11.6341\n","Epoch 76/100 completed. Discriminator Loss: 0.0600, Generator Loss: 11.6330\n","Epoch 77/100 completed. Discriminator Loss: 0.0586, Generator Loss: 11.6255\n","Epoch 78/100 completed. Discriminator Loss: 0.0577, Generator Loss: 11.5831\n","Epoch 79/100 completed. Discriminator Loss: 0.0570, Generator Loss: 11.5218\n","Epoch 80/100 completed. Discriminator Loss: 0.0564, Generator Loss: 11.4591\n","Epoch 81/100 completed. Discriminator Loss: 0.0560, Generator Loss: 11.3921\n","Epoch 82/100 completed. Discriminator Loss: 0.0551, Generator Loss: 11.3539\n","Epoch 83/100 completed. Discriminator Loss: 0.0535, Generator Loss: 11.3723\n","Epoch 84/100 completed. Discriminator Loss: 0.0518, Generator Loss: 11.4100\n","Epoch 85/100 completed. Discriminator Loss: 0.0501, Generator Loss: 11.4442\n","Epoch 86/100 completed. Discriminator Loss: 0.0493, Generator Loss: 11.4173\n","Epoch 87/100 completed. Discriminator Loss: 0.0487, Generator Loss: 11.3886\n","Epoch 88/100 completed. Discriminator Loss: 0.0480, Generator Loss: 11.3654\n","Epoch 89/100 completed. Discriminator Loss: 0.0472, Generator Loss: 11.3532\n","Epoch 90/100 completed. Discriminator Loss: 0.0457, Generator Loss: 11.4070\n","Epoch 91/100 completed. Discriminator Loss: 0.0428, Generator Loss: 11.5830\n","Epoch 92/100 completed. Discriminator Loss: 0.0379, Generator Loss: 11.9253\n","Epoch 93/100 completed. Discriminator Loss: 0.0318, Generator Loss: 12.3716\n","Epoch 94/100 completed. Discriminator Loss: 0.0253, Generator Loss: 12.8858\n","Epoch 95/100 completed. Discriminator Loss: 0.0210, Generator Loss: 13.2380\n","Epoch 96/100 completed. Discriminator Loss: 0.0215, Generator Loss: 13.2359\n","Epoch 97/100 completed. Discriminator Loss: 0.0240, Generator Loss: 13.1606\n","Epoch 98/100 completed. Discriminator Loss: 0.0248, Generator Loss: 13.0881\n","Epoch 99/100 completed. Discriminator Loss: 0.0255, Generator Loss: 13.0138\n","Epoch 100/100 completed. Discriminator Loss: 0.0258, Generator Loss: 12.9544\n","Evaluation Results: MSE = 0.1004, RMSE = 0.3168, MAE = 0.1078\n"]}],"source":["import urllib.request\n","import zipfile\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","\n","\n","movielens_data = pd.read_csv('/kaggle/input/dataset/Dataset.csv')\n","\n","user_item_matrix = movielens_data.pivot(index='user_id', columns='movieId', values='rating').fillna(0)\n","\n","\n","user_item_matrix_bin = (user_item_matrix > 3).astype(float)\n","\n","latent_dim = 128  \n","\n","generator = keras.Sequential([\n","    keras.Input(shape=(latent_dim,)),\n","    layers.Dense(128, activation=\"relu\"),\n","    layers.Dense(128),\n","    layers.LeakyReLU(),\n","    layers.Dropout(0.3),\n","    layers.Dense(128, activation=\"relu\"),\n","    layers.Dense(64, activation=\"relu\"),\n","    layers.Dense(user_item_matrix.shape[1], activation=\"sigmoid\")  \n","], name=\"generator\")\n","\n","discriminator = keras.Sequential([\n","    keras.Input(shape=(user_item_matrix.shape[1],)),\n","    layers.Dense(128, activation=\"relu\"),\n","    layers.Dense(64, activation=\"relu\"),\n","    layers.Dense(1, activation=\"sigmoid\")  \n","], name=\"discriminator\")\n","\n","class GAN(keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super().__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n","    \n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(GAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","    \n","    @property\n","    def metrics(self):\n","        return [self.d_loss_metric, self.g_loss_metric]\n","\n","    def train_step(self, real_matrix):\n","        batch_size = tf.shape(real_matrix)[0]\n","        \n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        generated_matrix = self.generator(random_latent_vectors)\n","\n","        combined_matrix = tf.concat([generated_matrix, real_matrix], axis=0)\n","        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)  \n","        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n","\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_matrix)\n","            d_loss = self.loss_fn(labels, predictions)\n","        \n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n","        \n","        misleading_labels = tf.zeros((batch_size, 1))\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(self.generator(random_latent_vectors))\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        \n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","\n","        self.d_loss_metric.update_state(d_loss)\n","        self.g_loss_metric.update_state(g_loss)\n","        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}\n","\n","gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n","gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","    loss_fn=keras.losses.BinaryCrossentropy()\n",")\n","\n","train_data, test_data = train_test_split(user_item_matrix_bin, test_size=0.2, random_state=42)\n","\n","\n","epochs = 100  \n","batch_size = 32\n","\n","num_samples = train_data.shape[0]\n","for epoch in range(epochs):\n","    d_loss_epoch = 0\n","    g_loss_epoch = 0\n","    batch_count = 0\n","    \n","    for i in range(0, num_samples, batch_size):\n","        real_matrix_batch = train_data[i:i + batch_size]\n","        metrics = gan.train_step(real_matrix_batch)\n","        d_loss_epoch += metrics['d_loss']\n","        g_loss_epoch += metrics['g_loss']\n","        batch_count += 1\n","\n","    d_loss_avg = d_loss_epoch / batch_count\n","    g_loss_avg = g_loss_epoch / batch_count\n","    \n","    print(f\"Epoch {epoch+1}/{epochs} completed. Discriminator Loss: {d_loss_avg:.4f}, Generator Loss: {g_loss_avg:.4f}\")\n","\n","def evaluate_gan(generator, real_data, latent_dim):\n"," \n","    num_samples = real_data.shape[0]\n","    latent_vectors = tf.random.normal(shape=(num_samples, latent_dim))\n","    generated_ratings = generator(latent_vectors).numpy()\n","    real_ratings_flat = real_data.values.flatten()\n","    generated_ratings_flat = generated_ratings.flatten()\n","    mse = mean_squared_error(real_ratings_flat, generated_ratings_flat)\n","    rmse = np.sqrt(mse)\n","    mae = mean_absolute_error(real_ratings_flat, generated_ratings_flat)\n","\n","    return {\"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae}\n","\n","evaluation_results = evaluate_gan(generator, test_data, latent_dim)\n","print(f\"Evaluation Results: MSE = {evaluation_results['MSE']:.4f}, RMSE = {evaluation_results['RMSE']:.4f}, MAE = {evaluation_results['MAE']:.4f}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T21:25:12.862510Z","iopub.status.busy":"2024-10-13T21:25:12.862123Z","iopub.status.idle":"2024-10-13T21:25:12.972124Z","shell.execute_reply":"2024-10-13T21:25:12.971078Z","shell.execute_reply.started":"2024-10-13T21:25:12.862476Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Models saved at /kaggle/working/\n"]}],"source":["import os\n","import pickle\n","\n","save_dir = '/kaggle/working/'  \n","os.makedirs(save_dir, exist_ok=True)\n","\n","generator_model_path = os.path.join(save_dir, 'gen_model.pkl')\n","discriminator_model_path = os.path.join(save_dir, 'disc_model.pkl')\n","gan_model_path = os.path.join(save_dir, 'gan_model.pkl')\n","\n","with open(generator_model_path, 'wb') as f:\n","    pickle.dump(generator, f)\n","    \n","with open(discriminator_model_path, 'wb') as f:\n","    pickle.dump(discriminator, f)\n","\n","with open(gan_model_path, 'wb') as f:\n","    pickle.dump(gan, f)\n","\n","print(f\"Models saved at {save_dir}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T21:24:07.444195Z","iopub.status.busy":"2024-10-13T21:24:07.443717Z","iopub.status.idle":"2024-10-13T21:24:17.577288Z","shell.execute_reply":"2024-10-13T21:24:17.576292Z","shell.execute_reply.started":"2024-10-13T21:24:07.444153Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1728854649.331936     179 service.cc:145] XLA service 0x7a442000e020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1728854649.331979     179 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","I0000 00:00:1728854649.331983     179 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 3s/step - loss: 0.2500"]},{"name":"stderr","output_type":"stream","text":["I0000 00:00:1728854650.712876     179 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.1841 - val_loss: 0.0326\n","Epoch 2/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - val_loss: 0.0330\n","Epoch 3/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - val_loss: 0.0330\n","Epoch 4/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0331\n","Epoch 5/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0330\n","Epoch 6/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0331\n","Epoch 7/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0330\n","Epoch 8/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0331\n","Epoch 9/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0331\n","Epoch 10/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0331\n","Epoch 11/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0331\n","Epoch 12/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - val_loss: 0.0331\n","Epoch 13/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0330\n","Epoch 14/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - val_loss: 0.0332\n","Epoch 15/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0330\n","Epoch 16/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0331\n","Epoch 17/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0338 - val_loss: 0.0331\n","Epoch 18/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0331\n","Epoch 19/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - val_loss: 0.0330\n","Epoch 20/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0331\n","Epoch 21/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0330\n","Epoch 22/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - val_loss: 0.0330\n","Epoch 23/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0329\n","Epoch 24/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0330\n","Epoch 25/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - val_loss: 0.0330\n","Epoch 26/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0329\n","Epoch 27/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0328\n","Epoch 28/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - val_loss: 0.0329\n","Epoch 29/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0328\n","Epoch 30/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0328\n","Epoch 31/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - val_loss: 0.0328\n","Epoch 32/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0328\n","Epoch 33/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - val_loss: 0.0327\n","Epoch 34/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - val_loss: 0.0327\n","Epoch 35/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0327\n","Epoch 36/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0327\n","Epoch 37/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0325\n","Epoch 38/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0324 - val_loss: 0.0326\n","Epoch 39/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0323\n","Epoch 40/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0322 - val_loss: 0.0321\n","Epoch 41/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0327 - val_loss: 0.0318\n","Epoch 42/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0317\n","Epoch 43/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0318 - val_loss: 0.0315\n","Epoch 44/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0317 - val_loss: 0.0314\n","Epoch 45/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0308\n","Epoch 46/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - val_loss: 0.0292\n","Epoch 47/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - val_loss: 0.0270\n","Epoch 48/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0287 - val_loss: 0.0255\n","Epoch 49/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0261 - val_loss: 0.0247\n","Epoch 50/50\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0256 - val_loss: 0.0246\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","\n","num_users, num_items = user_item_matrix.shape\n","\n","latent_dim = 128\n","\n","encoder_input = keras.Input(shape=(num_items,))\n","encoded = layers.Dense(256, activation=\"relu\")(encoder_input)\n","encoded = layers.Dense(128, activation=\"relu\")(encoded)\n","encoded = layers.Dense(latent_dim, activation=\"relu\")(encoded)\n","\n","encoder = keras.Model(encoder_input, encoded, name=\"encoder\")\n","\n","decoder_input = keras.Input(shape=(latent_dim,))\n","decoded = layers.Dense(128, activation=\"relu\")(decoder_input)\n","decoded = layers.Dense(256, activation=\"relu\")(decoded)\n","decoded = layers.Dense(num_items, activation=\"sigmoid\")(decoded)\n","\n","decoder = keras.Model(decoder_input, decoded, name=\"decoder\")\n","\n","autoencoder_input = keras.Input(shape=(num_items,))\n","encoded_output = encoder(autoencoder_input)\n","decoded_output = decoder(encoded_output)\n","\n","autoencoder = keras.Model(autoencoder_input, decoded_output, name=\"autoencoder\")\n","autoencoder.compile(optimizer='adam', loss='mse')\n","\n","autoencoder.fit(train_data, train_data, epochs=50, batch_size=32, validation_data=(test_data, test_data))\n","\n","latent_vectors = encoder.predict(user_item_matrix_bin)\n","\n","np.save('latent_vectors.npy', latent_vectors)\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T21:25:31.070782Z","iopub.status.busy":"2024-10-13T21:25:31.070349Z","iopub.status.idle":"2024-10-13T21:25:31.174304Z","shell.execute_reply":"2024-10-13T21:25:31.173308Z","shell.execute_reply.started":"2024-10-13T21:25:31.070741Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Recommended Movies for User 5:\n","1. E.T. the Extra-Terrestrial (1982)\n","2. Return of the Jedi (1983)\n","3. Fargo (1996)\n","4. Shawshank Redemption, The (1994)\n","5. My Left Foot (1989)\n","6. Star Wars (1977)\n","7. Hudsucker Proxy, The (1994)\n","8. Psycho (1960)\n","9. Toy Story (1995)\n","10. Ransom (1996)\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","import pickle\n","\n","latent_vectors = np.load('latent_vectors.npy')\n","\n","movies_data = pd.read_csv('/kaggle/input/dataset/Movie_Id_Titles.csv')\n","\n","movie_id_to_name = pd.Series(movies_data['title'].values, index=movies_data['item_id']).to_dict()\n","\n","latent_dim = latent_vectors.shape[1]  \n","num_movies = len(movie_id_to_name)\n","\n","with open(\"/kaggle/working/gen_model.pkl\", \"rb\") as file:\n","    generation = pickle.load(file)\n","    \n","def generate_movie_recommendations(user_id, latent_vectors, top_n=10):\n","  \n","    user_latent_vector = latent_vectors[user_id - 1]  \n","    generated_ratings = generation(np.expand_dims(user_latent_vector, axis=0)).numpy().flatten()\n","    top_movie_indices = np.argsort(generated_ratings)[::-1][:top_n]\n","    recommended_movie_ids = movie_id_to_name.keys()\n","    recommended_movie_names = [movie_id_to_name[list(recommended_movie_ids)[i]] for i in top_movie_indices]\n","    \n","    return recommended_movie_names\n","\n","user_id = 5  \n","recommended_movies = generate_movie_recommendations(user_id, latent_vectors, top_n=10)\n","\n","print(f\"Recommended Movies for User {user_id}:\")\n","for i, movie in enumerate(recommended_movies, 1):\n","    print(f\"{i}. {movie}\")\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T22:08:44.067831Z","iopub.status.busy":"2024-10-13T22:08:44.066847Z","iopub.status.idle":"2024-10-13T22:08:45.497973Z","shell.execute_reply":"2024-10-13T22:08:45.496875Z","shell.execute_reply.started":"2024-10-13T22:08:44.067785Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Pipeline saved successfully at /kaggle/working/all_pipeline.pkl\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import os\n","import pickle\n","\n","num_cols = ['rating']\n","categ_cols = ['item_id']  \n","\n","\n","categ_pipeline = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('ohe', OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore'))\n","])\n","\n","num_pipeline = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler()),\n","])\n","\n","all_pipeline = ColumnTransformer(transformers=[\n","    ('numerical', num_pipeline, num_cols),\n","    ('categorical', categ_pipeline, categ_cols)\n","])\n","\n","movielens_data = pd.read_csv('/kaggle/input/dataset/Dataset.csv')\n","\n","train_data, test_data = train_test_split(movielens_data, test_size=0.2, random_state=42)\n","\n","X_train_final = all_pipeline.fit_transform(train_data)\n","X_test_final = all_pipeline.transform(test_data)\n","\n","output_cols = num_cols + all_pipeline.named_transformers_['categorical'].named_steps['ohe'].get_feature_names_out(categ_cols).tolist()\n","pd.DataFrame(X_train_final, columns=output_cols)\n","\n","save_dir = os.getcwd()\n","pipeline_path = os.path.join(save_dir, 'all_pipeline.pkl')\n","with open(pipeline_path, 'wb') as f:\n","    pickle.dump(all_pipeline, f)\n","\n","print(f\"Pipeline saved successfully at {pipeline_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":1328499,"sourceId":2212151,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
